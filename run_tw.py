import yfinance as yf
import pandas as pd
import requests
import os
import sys
import time
import warnings
from xgboost import XGBRegressor
from datetime import datetime
from utils.market_calendar import is_market_open

warnings.filterwarnings("ignore")

# =========================
# åŸºæœ¬è¨­å®šèˆ‡ Secrets è®€å–
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(BASE_DIR, "tw_history.csv")
THREADS_TOKEN = os.getenv("THREADS_TOKEN", "").strip()

# =========================
# å·¥å…·å‡½æ•¸
# =========================
def pre_check():
    is_manual = os.getenv("GITHUB_EVENT_NAME") == "workflow_dispatch"
    if is_manual:
        print("âš¡ æ‰‹å‹•å¼·åˆ¶åŸ·è¡Œæ¨¡å¼ï¼šè·³éé–‹ä¼‘å¸‚æª¢æŸ¥ã€‚")
        return True
    if not is_market_open("TW"):
        print("ğŸ“Œ å› å‡æ—¥æˆ–ç¯€æ—¥ï¼Œè‚¡å¸‚æœªé–‹ç›¤ï¼Œåœæ­¢å‹•ä½œã€‚")
        return False
    return True

def calc_pivot(df):
    r = df.iloc[-20:]
    h, l, c = r["High"].max(), r["Low"].min(), r["Close"].iloc[-1]
    p = (h + l + c) / 3
    return round(2*p - h, 1), round(2*p - l, 1)

def get_tw_300():
    try:
        url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
        res = requests.get(url, timeout=10)
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df.iloc[1:]
        codes = df["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].str.split("ã€€").str[0]
        codes = codes[codes.str.len() == 4].head(300)
        return [f"{c}.TW" for c in codes]
    except Exception as e:
        print(f"âš ï¸ æŠ“å–ç¶²å€å¤±æ•—ï¼Œæ”¹ç”¨é è¨­æ¬Šå€¼è‚¡ã€‚")
        return ["2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW"]

# =========================
# Threads ç™¼å¸ƒå‡½æ•¸ (å«é‡è©¦é‚è¼¯)
# =========================
def post_to_threads(content):
    if not THREADS_TOKEN:
        print("â­ï¸ æ‰¾ä¸åˆ° THREADS_TOKENã€‚")
        return

    base_url = "https://graph.threads.net/v1.0"
    try:
        me_res = requests.get(f"{base_url}/me?fields=id&access_token={THREADS_TOKEN}")
        user_id = me_res.json().get("id")
        if not user_id: return

        payload = {"media_type": "TEXT", "text": content[:495], "access_token": THREADS_TOKEN}
        container_res = requests.post(f"{base_url}/{user_id}/threads", data=payload)
        creation_id = container_res.json().get("id")

        if not creation_id:
            print(f"âŒ å»ºç«‹å®¹å™¨å¤±æ•—ï¼API å›å‚³éŒ¯èª¤ï¼š{container_res.json()}")
            return

        print(f"âœ… å®¹å™¨æˆåŠŸï¼Œç­‰å¾… 20 ç§’...")
        time.sleep(20)

        publish_res = requests.post(
            f"{base_url}/{user_id}/threads_publish",
            data={"creation_id": creation_id, "access_token": THREADS_TOKEN}
        )
        if publish_res.status_code == 200:
            print("ğŸ‰ Threads AI 5æ—¥é æ¸¬å ±å‘Šç™¼å¸ƒæˆåŠŸï¼")
        else:
            print(f"âŒ ç™¼å¸ƒå¤±æ•—: {publish_res.text}")
    except Exception as e:
        print(f"ğŸ’¥ ç•°å¸¸: {e}")

# =========================
# ä¸»ç¨‹å¼
# =========================
def run():
    fixed = ["2330.TW", "2317.TW", "2454.TW", "0050.TW"]
    watch = list(dict.fromkeys(fixed + get_tw_300()))

    print(f"ğŸš€ å•Ÿå‹• AI 5æ—¥é æ¸¬åˆ†æ (ç›£æ§ {len(watch)} æª”)...")
    data = yf.download(watch, period="2y", auto_adjust=True, group_by="ticker", progress=False)

    results = {}
    feats = ["mom20", "bias", "vol_ratio"]
    for s in watch:
        try:
            df = data[s].dropna()
            if len(df) < 150: continue
            df["mom20"] = df["Close"].pct_change(20)
            df["bias"] = (df["Close"] - df["Close"].rolling(20).mean()) / df["Close"].rolling(20).mean()
            df["vol_ratio"] = df["Volume"] / df["Volume"].rolling(20).mean()
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            train = df.iloc[:-5].dropna()
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42)
            model.fit(train[feats], train["target"])
            pred = float(model.predict(df[feats].iloc[-1:])[0])
            results[s] = {"pred": pred, "price": round(df["Close"].iloc[-1], 2)}
        except: continue

    # --- å»ºç«‹å ±å‘Šå…§å®¹ (é‡é»ï¼šå»é™¤é»é¿å…è¢«ç•¶æˆç¶²å€) ---
    today_str = datetime.now().strftime("%Y-%m-%d")
    msg = f"ğŸ“Š AI å°è‚¡é æ¸¬å ±å‘Š ({today_str})\n"
    msg += "ğŸ¯ ç›®æ¨™ï¼šé æ¸¬æœªä¾† 5 å€‹äº¤æ˜“æ—¥æ¼²å¹…\n"
    msg += "--------------------------\n"
    
    horses = {k: v for k, v in results.items() if k not in fixed and v["pred"] > 0}
    top_5 = sorted(horses, key=lambda x: horses[x]["pred"], reverse=True)[:5]

    msg += "ğŸ† AI æµ·é¸ 5æ—¥æ½›åŠ›é»‘é¦¬ï¼š\n"
    for s in top_5:
        r = results[s]
        # é‡é»ï¼šå°‡ 2330.TW æ”¹æˆ 2330 TW é¿å…é€£çµéå¤š
        clean_name = s.replace(".", " ")
        msg += f"â€¢ {clean_name}: é ä¼° {r['pred']:+.2%} (ç¾åƒ¹:{r['price']})\n"

    msg += "\nğŸ“ˆ æ¯æ—¥ç›¤å¾Œè‡ªå‹•æµ·é¸ï¼Œæ•¸æ“šå®Œå…¨é€æ˜ã€‚"
    msg += f"\n\nğŸ”— åŠ å…¥ Discord äº¤æµï¼š\nhttps://discord.gg/aGzhSd2A5d"
    msg += "\n\n#AI #å°è‚¡ #é¸è‚¡æ©Ÿå™¨äºº #é‡åŒ–æŠ•è³‡ #5æ—¥é æ¸¬"

    post_to_threads(msg)

    # æ­·å²ç´€éŒ„å„²å­˜ä¿æŒä¸è®Š
    hist = [{"date":today_str,"symbol":s,"entry_price":results[s]["price"],"pred_ret":results[s]["pred"],"settled":False} for s in (top_5 + fixed) if s in results]
    if hist: pd.DataFrame(hist).to_csv(HISTORY_FILE, mode="a", header=not os.path.exists(HISTORY_FILE), index=False)

if __name__ == "__main__":
    if pre_check(): run()
