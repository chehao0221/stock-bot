import yfinance as yf
import pandas as pd
import requests
import os
import sys
import time
import warnings
from xgboost import XGBRegressor
from datetime import datetime
from utils.market_calendar import is_market_open

warnings.filterwarnings("ignore")

# =========================
# åŸºæœ¬è¨­å®šèˆ‡ Secrets è®€å–
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(BASE_DIR, "tw_history.csv")
# è®€å– GitHub Secrets çš„ Threads Token
THREADS_TOKEN = os.getenv("THREADS_TOKEN", "").strip()

# =========================
# å·¥å…·å‡½æ•¸
# =========================
def pre_check():
    """æª¢æŸ¥ä»Šæ—¥æ˜¯å¦é–‹ç›¤"""
    if not is_market_open("TW"):
        print("ğŸ“Œ å› å‡æ—¥æˆ–ç¯€æ—¥ï¼Œè‚¡å¸‚æœªé–‹ç›¤ï¼Œåœæ­¢å‹•ä½œ")
        return False
    return True

def calc_pivot(df):
    """è¨ˆç®—æ”¯æ’èˆ‡å£“åŠ›ä½"""
    r = df.iloc[-20:]
    h, l, c = r["High"].max(), r["Low"].min(), r["Close"].iloc[-1]
    p = (h + l + c) / 3
    return round(2*p - h, 1), round(2*p - l, 1)

def get_tw_300():
    """æŠ“å–å°è‚¡å‰ 300 æª”æ¸…å–®ç¶²å€"""
    try:
        url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
        res = requests.get(url, timeout=10)
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df.iloc[1:]
        codes = df["æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±"].str.split("ã€€").str[0]
        codes = codes[codes.str.len() == 4].head(300)
        return [f"{c}.TW" for c in codes]
    except Exception as e:
        print(f"âš ï¸ æŠ“å–ç¶²å€å¤±æ•—: {e}ï¼Œæ”¹ç”¨é è¨­æ¬Šå€¼è‚¡")
        return ["2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW"]

# =========================
# Threads ç™¼å¸ƒå‡½æ•¸
# =========================
def post_to_threads(content):
    if not THREADS_TOKEN:
        print("â­ï¸ æ‰¾ä¸åˆ° THREADS_TOKENï¼Œç„¡æ³•ç™¼å¸ƒåˆ° Threadsã€‚")
        return

    base_url = "https://graph.threads.net/v1.0"
    try:
        # 1. ç²å– User ID
        me_res = requests.get(f"{base_url}/me?fields=id&access_token={THREADS_TOKEN}")
        user_id = me_res.json().get("id")

        # 2. å»ºç«‹è²¼æ–‡å®¹å™¨ (ç¢ºä¿ä¸è¶…é 500 å­—)
        payload = {
            "media_type": "TEXT",
            "text": content[:490],
            "access_token": THREADS_TOKEN
        }
        container_res = requests.post(f"{base_url}/{user_id}/threads", data=payload)
        creation_id = container_res.json().get("id")

        print(f"â³ Threads å®¹å™¨å·²å»ºç«‹ï¼Œç­‰å¾… 15 ç§’é€²è¡Œä¼ºæœå™¨åŒæ­¥...")
        time.sleep(15)

        # 3. æ­£å¼ç™¼å¸ƒ
        publish_res = requests.post(
            f"{base_url}/{user_id}/threads_publish",
            data={"creation_id": creation_id, "access_token": THREADS_TOKEN}
        )
        if publish_res.status_code == 200:
            print("ğŸ‰ Threads AI å ±å‘Šç™¼å¸ƒæˆåŠŸï¼")
        else:
            print(f"âŒ Threads ç™¼å¸ƒå¤±æ•—: {publish_res.text}")
    except Exception as e:
        print(f"ğŸ’¥ Threads åŠŸèƒ½ç•°å¸¸: {e}")

# =========================
# ä¸»ç¨‹å¼
# =========================
def run():
    # è¨­å®šå›ºå®šç›£æ§çš„æ¬Šå€¼è‚¡
    fixed = ["2330.TW", "2317.TW", "2454.TW", "0050.TW", "2308.TW", "2382.TW"]
    watch = list(dict.fromkeys(fixed + get_tw_300()))

    print(f"ğŸš€ é–‹å§‹åˆ†æ {len(watch)} æª”å°è‚¡æ¨™çš„...")
    data = yf.download(watch, period="2y", auto_adjust=True, group_by="ticker", progress=False)

    feats = ["mom20", "bias", "vol_ratio"]
    results = {}

    for s in watch:
        try:
            df = data[s].dropna()
            if len(df) < 150: continue

            df["mom20"] = df["Close"].pct_change(20)
            df["bias"] = (df["Close"] - df["Close"].rolling(20).mean()) / df["Close"].rolling(20).mean()
            df["vol_ratio"] = df["Volume"] / df["Volume"].rolling(20).mean()
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1

            train = df.iloc[:-5].dropna()
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42)
            model.fit(train[feats], train["target"])

            pred = float(model.predict(df[feats].iloc[-1:])[0])
            sup, res_price = calc_pivot(df)

            results[s] = {
                "pred": pred,
                "price": round(df["Close"].iloc[-1], 2),
                "sup": sup,
                "res": res_price
            }
        except:
            continue

    # --- å»ºç«‹å ±å‘Šå…§å®¹ ---
    today_str = datetime.now().strftime("%Y-%m-%d")
    msg = f"ğŸ“Š AI å°è‚¡ç›¤å¾Œå ±å‘Š ({today_str})\n"
    msg += "--------------------------\n"
    
    horses = {k: v for k, v in results.items() if k not in fixed and v["pred"] > 0}
    top_5 = sorted(horses, key=lambda x: horses[x]["pred"], reverse=True)[:5]

    msg += "ğŸ† AI æµ·é¸æ½›åŠ›é»‘é¦¬ï¼š\n"
    for s in top_5:
        r = results[s]
        msg += f"â€¢ {s}: é ä¼° {r['pred']:+.2%}\n  (ç¾åƒ¹:{r['price']} æ”¯æ’:{r['sup']})\n"

    msg += "\nğŸ” æ¬Šå€¼è‚¡ç›£æ§ï¼š\n"
    for s in fixed[:3]: # ç‚ºç¬¦åˆå­—æ•¸é™åˆ¶ï¼Œåƒ…å–å‰ä¸‰
        if s in results:
            r = results[s]
            msg += f"â€¢ {s}: é ä¼° {r['pred']:+.2%}\n"

    msg += "\nğŸ’¡ AI æ¨¡å‹åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ã€‚"

    # --- åŸ·è¡Œ Threads ç™¼å¸ƒ ---
    post_to_threads(msg)

    # --- å„²å­˜æ­·å²ç´€éŒ„è‡³ CSV ---
    hist = [{
        "date": today_str,
        "symbol": s,
        "entry_price": results[s]["price"],
        "pred_ret": results[s]["pred"],
        "settled": False
    } for s in (top_5 + fixed) if s in results]

    if hist:
        new_df = pd.DataFrame(hist)
        new_df.to_csv(HISTORY_FILE, mode="a", header=not os.path.exists(HISTORY_FILE), index=False)
        print(f"âœ… æ­·å²æ•¸æ“šå·²å­˜å…¥ {HISTORY_FILE}")

if __name__ == "__main__":
    if pre_check():
        run()
